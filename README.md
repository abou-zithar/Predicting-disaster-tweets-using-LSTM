<h1> Requirements</h1>

- Load the dataset
- Check head and info of the data
- Is there a missing data [how many and the precentage if there]?
- How many data in each class?
- Get the top 15 locations of the data
- Get the top 15 keyword in the data
- What are the most common words?
- What are the most common stop words?
- Use nlp to prepare dataset [tokenization, pad sequence, etc.]
- Prepare train, test sets
- Train your LSTM structure
- Evaluate the model and make predictions
- Save your model
- Post your project into GitHub
<hr>
<h1> columns Description</h1>

- id ===> a unique identifier for each tweet
- text ===> the text of the tweet
- location ===> the location the tweet was sent from (may be blank)
- keyword ===> a particular keyword from the tweet (may be blank)
- target ===> in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)

<hr>
